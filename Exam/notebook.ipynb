{"cells":[{"source":"# Data Scientist Associate Practical Exam Submission\n\nUse this template to complete your analysis and write up your summary for submission.\n","metadata":{},"id":"1e20b471-43f1-4e12-afb1-aa7825d8cc69","cell_type":"markdown"},{"source":"## Task 1 \n*Write your description here*\nthe column names and their respective answers are written:\n# booking_id:\n- a. The description provided in the table is \"Nominal,\" but the actual description is \"Continuous.\"\n- b. There are no missing values in this column.\n- c. Since the nature of the booking_id is typically a unique identifier, no action is needed to make values match the description.\n\n# months_as_member:\n- a. The description provided in the table is \"Discrete,\" and the actual description is \"Continuous,\" which matches.\n- b. There are no missing values in this column.\n- c. No action is needed since the actual description matches the expected description.\n# \n# weight:\n- a. The description provided in the table is \"Continuous,\" and the actual description is \"Continuous,\" which matches.\n- b. There are 20 missing values in this column.\n- c. To make values match the description, the missing values in the weight column have been replaced with the mean weight of the dataset.\n\n# days_before:\n- a. The description provided in the table is \"Discrete,\" but the actual description is \"Unknown.\"\n- b. There are no missing values in this column.\n- c. Since the actual description is \"Unknown,\" no action is needed to make values match the description.\n\n# day_of_week:\n- a. The description provided in the table is \"Nominal,\" but the actual description is \"Unknown.\"\n- b. There are no missing values in this column.\n- c. To make values match the description, missing values in the day_of_week column have been replaced with \"unknown.\"\n\n# time:\n- a. The description provided in the table is \"Ordinal,\" but the actual description is \"Unknown.\"\n- b. There are no missing values in this column.\n- c. To make values match the description, missing values in the time column have been replaced with \"unknown.\"\n\n# category:\n- a. The description provided in the table is \"Nominal,\" but the actual description is \"Unknown.\"\n- b. There are no missing values in this column.\n- c. To make values match the description, missing values in the category column have been replaced with \"unknown.\"\n\n# attended:\n- a. The description provided in the table is \"Nominal,\" and the actual description is \"Nominal,\" which matches.\n- b. There are no missing values in this column.\n- c. No action is needed since the actual description matches the expected description.\n","metadata":{},"id":"836353de-534f-460d-b9ce-e92cc3646c65","cell_type":"markdown"},{"source":"## Task 2\n*Write your description here*\n`import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a countplot to visualize the number of bookings attended the class\nplt.figure(figsize=(8, 6))\nsns.countplot(data=df, x='attended')\nplt.title('Attendance Distribution')\nplt.xlabel('Attended')\nplt.ylabel('Count')\nplt.show()\n`\n![Screenshot 2023-10-06 120628](Screenshot%202023-10-06%20120628.png)\n# task A\n\na. The category \"0\" of the variable \"attended\" has the most observations. This means that there are more bookings where members did not attend the class (category 0) compared to the bookings where members attended the class (category 1).\n# task B\nb. The observations are not balanced across categories of the variable \"attended.\" Since category \"0\" has a significantly larger count compared to category \"1,\" the dataset is imbalanced. There are more instances of members not attending the class than attending it. Imbalanced datasets can sometimes pose challenges when building predictive models, especially for rare events (in this case, attendance). It's important to keep this class imbalance in mind when working with the data and choosing an appropriate modeling approach.\n","metadata":{},"id":"0944d9ab-ff5a-4dd3-bd52-e27b91d68581","cell_type":"markdown"},{"source":"## Task 3\n*Write your description here*\n![Screenshot 2023-10-06 121127](Screenshot%202023-10-06%20121127.png)\n\n it means that there is a longer tail on the right side of the distribution, and the majority of members have lower values of months as a member, with a few members having significantly higher values.\n\nIn practical terms, this suggests that most members have relatively short membership durations, while a smaller number of members have been with the fitness club for an extended period. Understanding the skewness of this distribution can be valuable for business decision-making, marketing strategies, and member retention efforts, as it highlights the diversity in membership duration.\n","metadata":{},"id":"c509bc83-41a5-42cf-a865-08dcf8229a16","cell_type":"markdown"},{"source":"## Task 4\n`*Write your description here*\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a box plot to visualize the relationship between attendance and months_as_member\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=df, x='attended', y='months_as_member')\nplt.title('Relationship between Attendance and Months as a Member')\nplt.xlabel('Attended')\nplt.ylabel('Months as Member')\nplt.xticks([0, 1], ['Not Attended', 'Attended'])\n\nplt.show()`\nFrom the box plot, we can observe the following relationship:\n\nAttendance and Membership Duration: Among attendees, there are two distinct subgroups with different median membership durations: around 40 months and around 80 months. This suggests that attendees can be further divided based on their membership duration.\nComparison with Non-Attendees: On the other hand, non-attendees have a median membership duration of approximately 20 months, which is shorter than either subgroup of attendees. This indicates that non-attendees tend to be relatively newer members.\nOutliers: Additionally, some attendees have significantly longer membership durations, reaching up to 120 months. These outliers may represent exceptional cases.\nOverall, there appears to be a clear relationship between attendance and membership duration. Attendees generally have longer membership durations, and within the attendee group, there are distinct subgroups based on membership duration.","metadata":{},"id":"17cca003-71ad-4d7e-989b-09aa51ae0aba","cell_type":"markdown"},{"source":"## Task 5\n*Write your description here*\nThe type of machine learning problem for this task is a classification problem.\n\nIn a classification problem, the goal is to predict the category or class to which a data point (in this case, a member) belongs. In this specific scenario, the task is to predict whether a member will attend the fitness class or not. The target variable, \"attended,\" is nominal and binary, taking values 0 (not attended) or 1 (attended). The objective is to build a predictive model that can classify members into one of these two categories based on various features such as \"months_as_member,\" \"weight,\" \"days_before,\" \"day_of_week,\" \"time,\" and \"category.\"\n\nClassification is the appropriate type of problem for predicting a binary outcome like attendance (yes or no) in this context. The model will learn patterns and relationships in the dataset to make predictions about whether a member is likely to attend the class or not, based on the provided features.\n\n\n","metadata":{},"id":"66e07a44-f276-4516-87ce-e460d3f1a33a","cell_type":"markdown"},{"source":"## Task 6\n*Write your description here*\nThe baseline model's performance metrics are as follows:\n\nAccuracy: 0.7619 (approximately 76.19%)\n\nConfusion Matrix:\n\nTrue Negatives (TN): 189\nFalse Positives (FP): 22\nFalse Negatives (FN): 48\nTrue Positives (TP): 35\nClassification Report:\n\nPrecision for class 0: 0.80\n\nRecall for class 0: 0.90\n\nF1-score for class 0: 0.84\n\nPrecision for class 1: 0.61\n\nRecall for class 1: 0.42\n\nF1-score for class 1: 0.50\n\nThe accuracy of the model is 76.19%, which means it correctly predicts whether a member will attend or not in about 76.19% of the cases. The precision, recall, and F1-score for each class provide more detailed information about the model's performance, especially when dealing with imbalanced datasets like this one.\n\nFor class 0 (attended = 0):\n\nPrecision: 0.80\nRecall: 0.90\nF1-score: 0.84\nFor class 1 (attended = 1):\n\nPrecision: 0.61\nRecall: 0.42\nF1-score: 0.50\nThese metrics give insights into how well the model is performing for each class. In this case, the model has a higher precision and recall for class 0 (members who did not attend) compared to class 1 (members who attended). Further model tuning or exploring different algorithms may help improve the performance, especially for class 1, if necessary.","metadata":{},"id":"8b20fa2e-da87-4cf4-9591-157a0837891e","cell_type":"markdown"},{"source":"import pandas as pd\n\n# Load the raw dataset\ndf = pd.read_csv(\"fitness_class_2212.csv\")  \n\n# Preprocess the data\n# Handle missing values in the \"weight\" column by replacing \"NA\" with the overall average weight\naverage_weight = df[\"weight\"].mean()\ndf[\"weight\"].replace(\"NA\", average_weight, inplace=True)\n\n# Extract numerical values from the \"days_before\" column\ndf['days_before'] = df['days_before'].str.extract('(\\d+)').astype(float)\n\n# Perform one-hot encoding for the \"day_of_week\" column\ndf = pd.get_dummies(df, columns=['day_of_week'], drop_first=True)\n\n# Map the \"time\" column to numerical values (e.g., \"AM\" -> 0, \"PM\" -> 1)\ndf[\"time\"] = df[\"time\"].map({\"AM\": 0, \"PM\": 1})\n\n# Map the \"category\" column to numerical values (you can use one-hot encoding if needed)\ncategory_mapping = {\"Yoga\": 0, \"Aqua\": 1, \"Strength\": 2, \"HIIT\": 3, \"Cycling\": 4}\ndf[\"category\"] = df[\"category\"].map(category_mapping)\n\n# Convert the \"attended\" column to numeric values (0 and 1)\ndf[\"attended\"] = df[\"attended\"].replace({\"-0\": 0, 0: 0, 1: 1})\n\n# Drop rows with missing values\ndf = df.dropna()\n\n# Split the data into features (X) and target (y)\nX = df.drop(columns=[\"attended\"])\ny = df[\"attended\"]\n\n# Now you can proceed with splitting the data and training your model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train a logistic regression model\nbaseline_model = LogisticRegression(random_state=42)\nbaseline_model.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = baseline_model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(\"Classification Report:\")\nprint(class_report)\n","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":290,"type":"stream"}}},"id":"76b4446c-9c17-4aa7-8119-8d33c51a6593","cell_type":"code","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy: 0.7619047619047619\nConfusion Matrix:\n[[189  22]\n [ 48  35]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.90      0.84       211\n           1       0.61      0.42      0.50        83\n\n    accuracy                           0.76       294\n   macro avg       0.71      0.66      0.67       294\nweighted avg       0.75      0.76      0.75       294\n\n"}]},{"source":"## Task 7\n*Write your description here*","metadata":{},"id":"b7f0dcc4-98c7-43fe-8ee2-629aac60c421","cell_type":"markdown"},{"source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train a Random Forest Classifier\ncomparison_model = RandomForestClassifier(random_state=42)\ncomparison_model.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = comparison_model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(\"Classification Report:\")\nprint(class_report)\n\n","metadata":{"executionCancelledAt":null,"executionTime":212,"lastExecutedAt":1696577721865,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train a Random Forest Classifier\ncomparison_model = RandomForestClassifier(random_state=42)\ncomparison_model.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = comparison_model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(\"Classification Report:\")\nprint(class_report)\n\n","outputsMetadata":{"0":{"height":290,"type":"stream"}}},"id":"3d5953c8-9f51-426c-a597-b41bd742e4d1","cell_type":"code","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy: 0.7448979591836735\nConfusion Matrix:\n[[181  30]\n [ 45  38]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.86      0.83       211\n           1       0.56      0.46      0.50        83\n\n    accuracy                           0.74       294\n   macro avg       0.68      0.66      0.67       294\nweighted avg       0.73      0.74      0.74       294\n\n"}]},{"source":"## Task 8\n*Write your description here*\nHere's an explanation of why I chose these two models:\n\n# Logistic Regression Model:\n\nLogistic Regression is a simple yet effective classification algorithm that is well-suited for binary classification problems like predicting whether members will attend a fitness class (attended or not attended).\nIt provides probabilities for the target classes, making it easy to interpret the model's predictions.\nLogistic Regression is computationally efficient and doesn't require a large amount of data to perform well.\nIt serves as a baseline model, and it's often a good starting point to establish a benchmark for more complex models.\n# Random Forest Classifier:\n\nRandom Forest is an ensemble learning technique that combines multiple decision trees to improve predictive accuracy and reduce overfitting.\nIt can handle both binary and multiclass classification problems effectively.\nRandom Forests are robust to outliers, missing values, and irrelevant features, making them suitable for real-world datasets with noise and complexities.\nThey provide feature importance scores, which can help identify which features are most influential in making predictions.\nRandom Forests can capture complex relationships in the data and often outperform simpler models like Logistic Regression.\nThe choice between these two models is also influenced by the need for comparison. By demonstrating both Logistic Regression and Random Forest Classifier, I provide a comparison between a straightforward linear model and a more complex ensemble model. This comparison allows you to assess whether a more sophisticated model like Random Forest offers any significant improvement in prediction accuracy for this specific task.","metadata":{},"id":"5cec4b2d-86fd-4ce3-9f9c-e9ab2ec0e436","cell_type":"markdown"},{"source":"## Task 9\n*Write your description here*","metadata":{},"id":"84fc2a09-ea39-4a6f-85b2-5d17957e1ac5","cell_type":"markdown"},{"source":"# Start coding here... \nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Initialize and train the Logistic Regression model\nlogistic_model = LogisticRegression(random_state=42)\nlogistic_model.fit(X_train, y_train)\n\n# Make predictions using Logistic Regression\nlogistic_preds = logistic_model.predict(X_test)\n\n# Initialize and train the Random Forest Classifier model\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Make predictions using Random Forest Classifier\nrf_preds = rf_model.predict(X_test)\n\n# Evaluate and compare the models\ndef evaluate_model(model_name, y_true, y_pred):\n    accuracy = accuracy_score(y_true, y_pred)\n    cm = confusion_matrix(y_true, y_pred)\n    cr = classification_report(y_true, y_pred)\n    roc_auc = roc_auc_score(y_true, y_pred)\n    \n    print(f\"Performance Metrics for {model_name}:\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(\"Confusion Matrix:\")\n    print(cm)\n    print(\"Classification Report:\")\n    print(cr)\n    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n    print(\"\\n\")\n\n# Evaluate Logistic Regression\nevaluate_model(\"Logistic Regression\", y_test, logistic_preds)\n\n# Evaluate Random Forest Classifier\nevaluate_model(\"Random Forest Classifier\", y_test, rf_preds)\n","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":518,"type":"stream"}}},"id":"246f2368-09ae-4cac-bdb5-7daacb0b2faf","cell_type":"code","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"Performance Metrics for Logistic Regression:\nAccuracy: 0.7732\nConfusion Matrix:\n[[285  28]\n [ 72  56]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.91      0.85       313\n           1       0.67      0.44      0.53       128\n\n    accuracy                           0.77       441\n   macro avg       0.73      0.67      0.69       441\nweighted avg       0.76      0.77      0.76       441\n\nROC AUC Score: 0.6740\n\n\nPerformance Metrics for Random Forest Classifier:\nAccuracy: 0.7574\nConfusion Matrix:\n[[275  38]\n [ 69  59]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.88      0.84       313\n           1       0.61      0.46      0.52       128\n\n    accuracy                           0.76       441\n   macro avg       0.70      0.67      0.68       441\nweighted avg       0.74      0.76      0.75       441\n\nROC AUC Score: 0.6698\n\n\n"}]},{"source":"## Task 10\n*Write your description here*\nthe Logistic Regression model and the Random Forest Classifier model have fairly similar performance, but there are some differences to consider:\n\n**Accuracy:** The Logistic Regression model has a slightly higher accuracy of approximately 0.7732, while the Random Forest Classifier has an accuracy of approximately 0.7574. In terms of overall correctness, the Logistic Regression model performs slightly better.\n\n**Precision and Recall:** For both models, the precision and recall scores are relatively similar for class 0 (attended) and class 1 (did not attend). However, for class 1, the Logistic Regression model has slightly higher precision and recall compared to the Random Forest Classifier. This indicates that the Logistic Regression model is better at correctly identifying instances of class 1.\n\n**F1-Score**: The F1-score balances precision and recall. For class 1, the Logistic Regression model has a higher F1-score (approximately 0.53) compared to the Random Forest Classifier (approximately 0.52). This suggests that the Logistic Regression model achieves a better balance between precision and recall for class 1.\n\n**ROC AUC Score**: Both models have similar ROC AUC scores, with the Logistic Regression model having a score of approximately 0.6740, and the Random Forest Classifier having a score of approximately 0.6698. ROC AUC measures the ability of the model to distinguish between the two classes, and again, both models have similar performance in this aspect.\n\nIn summary, while both models perform relatively similarly in terms of accuracy and ROC AUC score, the Logistic Regression model performs slightly better in terms of precision, recall, and F1-score for class 1 (did not attend). Therefore, based on the provided metrics, the Logistic Regression model appears to be the better choice for predicting class attendance. However, it's important to consider other factors such as interpretability, computational complexity, and the specific goals of the application when choosing a model.","metadata":{},"id":"feb9e1eb-8913-43b8-a280-a369cf10631e","cell_type":"markdown"},{"source":"## ✅  When you have finished...\n- Publish your Workspace using the option on the left\n- Check the published version of your report:\n\t- Can you see everything you want us to grade?\n    - Are all the graphics visible?\n- Review the grading rubric. Have you included everything that will be graded?\n- Head back to the [Certification dashboard](https://app.datacamp.com/certification) to submit your practical exam","metadata":{},"id":"c42a2f84-876d-4002-9d9b-990873351e5f","cell_type":"markdown"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}